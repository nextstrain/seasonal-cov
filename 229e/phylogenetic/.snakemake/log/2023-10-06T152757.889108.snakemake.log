Building DAG of jobs...
Using shell: /Users/katekistler/.nextstrain/runtimes/conda/env/bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job stats:
job       count
------  -------
filter        1
total         1

Select jobs to execute...

[Fri Oct  6 15:27:58 2023]
Job 0: 
        Filtering to
          - 5000 sequence(s) per country
          - minimum genome length of 20000
        
Reason: Updated input files: ../ingest/results/sequences.fasta, ../ingest/results/subset_metadata.tsv


        augur filter             --sequences ../ingest/results/sequences.fasta             --metadata ../ingest/results/subset_metadata.tsv             --exclude config/dropped_strains.txt             --exclude-where 'host!=Homo sapiens'             --output results/filtered.fasta             --group-by country             --sequences-per-group 5000             --min-length 20000
        
[Fri Oct  6 15:27:59 2023]
Finished job 0.
1 of 1 steps (100%) done
Complete log: .snakemake/log/2023-10-06T152757.889108.snakemake.log
